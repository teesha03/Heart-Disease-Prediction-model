import numpy as np # linear algebra
import pandas as pd
import os
for dirname, _, filenames in os.walk('/content/heart.csv'):
    for filename in filenames:
        print(os.path.join(dirname, filename))


!pip install awscli


!aws configure


import os

os.environ['AWS_ACCESS_KEY_ID'] = '.'
os.environ['AWS_SECRET_ACCESS_KEY'] = '.'

!aws sts get-caller-identity


!pip install sagemaker


import sagemaker
import boto3
from sagemaker import get_execution_role
from sagemaker.amazon.amazon_estimator import get_image_uri
from sagemaker.session import s3_input, Session

# Explicitly set the region
region = 'us-east-1' # Replace with your desired region

# Configure the boto3 session with the region
boto_session = boto3.Session(region_name=region)

# Pass the boto3 session to the SageMaker session
sm_boto3 = boto3.client('sagemaker', region_name=region)
sess = sagemaker.Session(boto_session=boto_session) # Pass the boto3 session here

bucket = 'mysagemakerbucket55'
prefix = 'heart-disease-prediction'
print("using bucket"+ bucket)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
import os
import yellowbrick
import pickle

from matplotlib.collections import PathCollection
from statsmodels.graphics.gofplots import qqplot
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier,ExtraTreesClassifier
from sklearn.metrics import classification_report, accuracy_score
from yellowbrick.classifier import PrecisionRecallCurve, ROCAUC, ConfusionMatrix
from yellowbrick.style import set_palette
from yellowbrick.model_selection import LearningCurve, FeatureImportances
from yellowbrick.contrib.wrapper import wrap

# --- Libraries Settings ---
warnings.filterwarnings('ignore')
sns.set_style('whitegrid')
plt.rcParams['figure.dpi']=100
set_palette('dark')

!pip install ipykernel

# --- Importing Dataset ---
df = pd.read_csv("/content/heart.csv")

# --- Reading Dataset ---
df.head().style.background_gradient(cmap='Reds').set_properties(**{'font-family': 'Segoe UI'}).hide(axis="index") # Use hide() with axis="index" to hide the index


# --- Create List of Color Palletes ---
red_grad = ['#FF0000', '#BF0000', '#800000', '#400000', '#000000']
pink_grad = ['#8A0030', '#BA1141', '#FF5C8A', '#FF99B9', '#FFDEEB']
purple_grad = ['#4C0028', '#7F0043', '#8E004C', '#A80059', '#C10067']
color_mix = ['#F38BB2', '#FFB9CF', '#FFD7D7', '#F17881', '#E7525B']
black_grad = ['#100C07', '#3E3B39', '#6D6A6A', '#9B9A9C', '#CAC9CD']
# --- Plot Color Palletes --
sns.palplot(red_grad)
sns.palplot(pink_grad)
sns.palplot(purple_grad)
sns.palplot(color_mix)
sns.palplot(black_grad)

# --- Print Dataset Info ---
print('\033[1m'+'.: Dataset Info :.'+'\033[0m')
print('*' * 30)
print('Total Rows:'+'\033[1m', df.shape[0])
print('\033[0m'+'Total Columns:'+'\033[1m', df.shape[1])
print('\033[0m'+'*' * 30)
print('\n')

# --- Print Dataset Detail ---
print('\033[1m'+'.: Dataset Details :.'+'\033[0m')
print('*' * 30)
df.info(memory_usage = False)

# --- Fix Data Types ---
lst=['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']
df[lst] = df[lst].astype(object)

### <div style="font-family: Trebuchet MS; background-color: #FF5C8A; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Descriptive Statistics üìè</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
    üëâ This section will show <b>descriptive statistics</b> of numerical variables.
</div>

# --- Descriptive Statistics ---
df.select_dtypes(exclude='object').describe().T.style.background_gradient(cmap='PuRd').set_properties(**{'font-family': 'Segoe UI'})

## <div style="font-family: Trebuchet MS; background-color: #BA1141; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Heart Disease Distribution based on Gender üíâüë´</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
üëâ This section will show heart disease distribution based on gender.
</div>

# --- Labels Settings ---
labels = ['False', 'True']
label_gender = np.array([0, 1])
label_gender2 = ['Male', 'Female']

# --- Creating Bar Chart ---
ax = pd.crosstab(df.sex, df.target).plot(kind='bar', figsize=(8, 5),
                                         color=color_mix[2:4],
                                         edgecolor=black_grad[2], alpha=0.85)
# --- Bar Chart Settings ---
for rect in ax.patches:
    ax.text (rect.get_x()+rect.get_width()/2,
             rect.get_height()+1.25,rect.get_height(),
             horizontalalignment='center', fontsize=10)

plt.suptitle('Heart Disease Distribution based on Gender', fontweight='heavy',
             x=0.065, y=0.98, ha='left', fontsize='16', fontfamily='sans-serif',
             color=black_grad[0])
plt.title('Female tend to have heart diseases compared to Male. In male, the distribution is not imbalanced compared to female\nthat have almost the same distribution',
          fontsize='8', fontfamily='sans-serif', loc='left', color=black_grad[1])
plt.tight_layout(rect=[0, 0.04, 1, 1.025])
plt.xlabel('Gender (Sex)', fontfamily='sans-serif', fontweight='bold',
           color=black_grad[1])
plt.ylabel('Total', fontfamily='sans-serif', fontweight='bold',
           color=black_grad[1])
plt.xticks(label_gender, label_gender2, rotation=0)
plt.grid(axis='y', alpha=0.4)
plt.grid(axis='x', alpha=0)
plt.legend(labels=labels, title='$\\bf{Target}$', fontsize='8',
           title_fontsize='9', loc='upper left', frameon=True);

## <div style="font-family: Trebuchet MS; background-color: #BA1141; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Heart Disease Scatter Plot based on Age üíâüë¥</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
üëâ This section will show <b>scatter plot</b> of patients with heart diseases based on age.
</div>

# -- Scatter Plot Size & Titles Settings ---
plt.figure(figsize=(10, 8))
plt.suptitle('Heart Disease Scatter Plot based on Age', fontweight='heavy',
             x=0.048, y=0.98, ha='left', fontsize='16', fontfamily='sans-serif',
             color=black_grad[0])
plt.title('Based on age, patients with and without heart diseases mostly between 50-70 years old. Patients with heart diseases tend to have high heart rate\ncompared to patients with no heart diseases.',
          fontsize='8', fontfamily='sans-serif', loc='left', color=black_grad[1])
plt.tight_layout(rect=[0, 0.04, 1, 1.01])

# --- Creating Scatter Plot ---
plt.scatter(x=df.age[df.target==0], y=df.thalach[(df.target==0)], c=pink_grad[0])
plt.scatter(x=df.age[df.target==1], y=df.thalach[(df.target==1)], c=pink_grad[2])

# --- Scatter Plot Legend & Labels Settings ---
plt.legend(['False', 'True'], title='$\\bf{Type}$', fontsize='7',
           title_fontsize='8', loc='upper right', frameon=True)
plt.xlabel('Age', fontweight='bold', fontsize='11',
           fontfamily='sans-serif', color=black_grad[1])
plt.ylabel('Max. Heart Rate', fontweight='bold', fontsize='11',
           fontfamily='sans-serif', color=black_grad[1])
plt.ticklabel_format(style='plain', axis='both')
plt.grid(axis='both', alpha=0.4, lw=0.5)
plt.show();

## <div style="font-family: Trebuchet MS; background-color: #BA1141; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Heatmap üî•</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
    üëâ Below is <b>correlation map/heatmap of numerical variables</b> to show correlation level/values for each variables with others.
</div>

# --- Correlation Map (Heatmap) ---
plt.figure(figsize=(14, 9))
sns.heatmap(df.corr(), annot=True, cmap='Reds', linewidths=0.1)
plt.suptitle('Correlation Map of Numerical Variables', fontweight='heavy',
             x=0.03, y=0.98, ha='left', fontsize='16', fontfamily='sans-serif',
             color=black_grad[0])
plt.title('Resting blood pressure, cholestoral, and "oldpeak" have moderate relationship with age.',
          fontsize='10', fontfamily='sans-serif', loc='left', color=black_grad[1])
plt.tight_layout(rect=[0, 0.04, 1, 1.01])

# <div style="font-family: Trebuchet MS; background-color: #BA1141; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Dataset Pre-processing ‚öô</div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
    üëâ This section will <b>prepare the dataset</b> before building the machine learning models.
</div>

# --- Creating Dummy Variables for cp, thal and slope ---
cp = pd.get_dummies(df['cp'], prefix='cp')
thal = pd.get_dummies(df['thal'], prefix='thal')
slope = pd.get_dummies(df['slope'], prefix='slope')

# --- Merge Dummy Variables to Main Data Frame ---
frames = [df, cp, thal, slope]
df = pd.concat(frames, axis = 1)

# --- Display New Data Frame ---
df.head().style.hide(axis="index").background_gradient(cmap='PuRd').set_properties(**{'font-family': 'Segoe UI'})

## <div style="font-family: Trebuchet MS; background-color: #FF5C8A; color: #FFFFFF; padding: 12px; line-height: 1.5;"> Dropping Unnecessary Variables üîª </div>
<div style="font-family: Segoe UI; line-height: 2; color: #000000; text-align: justify">
    üëâ The <b>variables that unnecessary will be deleted</b>.
</div>

# --- Drop Unnecessary Variables ---
df = df.drop(columns = ['cp', 'thal', 'slope'])

# --- Display New Data Frame ---
df.head().style.background_gradient(cmap='Reds').hide(axis="index").set_properties(**{'font-family': 'Segoe UI'})

# --- Seperating Dependent Features ---
x = df.drop(['target'], axis=1)
y = df['target']

# --- Data Normalization using Min-Max Method ---
x = MinMaxScaler().fit_transform(x)

# --- Splitting Dataset into 80:20 ---
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)

import pandas as pd
# --- Saving Training & Testing Datasets as CSV ---
x_train_df = pd.DataFrame(x_train)
x_test_df = pd.DataFrame(x_test)

train_file = 'train.csv'
test_file = 'test.csv'

x_train_df.to_csv(train_file, index=False)
x_test_df.to_csv(test_file, index=False)

sk_prefix= "sagemaker/heart-disease-prediction/sklearncontainer/"
trainpath = sess.upload_data(path=train_file,bucket=bucket, key_prefix=sk_prefix+"train")
testpath = sess.upload_data(path=test_file,bucket=bucket, key_prefix=sk_prefix+"test")
print(trainpath)
print(testpath)

%%writefile script.py
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score,recall_score
import sklearn
import joblib
import boto3
import pathlib
from io import StringIO
import argparse
import os
import pandas as pd
import numpy as np
def model_fn(model_dir):
  clf = joblib.load(os.path.join(model_dir, "model.joblib"))
  return clf

  if __name__ == '__main__':
    print("[INFO] Extracting arguments")
    parser = argparse.ArgumentParser()

    parser.add_argument('--model_dir', type=str, default=os.environ.get('SM_MODEL_DIR'))
    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))
    parser.add_argument('--test', type=str, default=os.environ.get('SM_CHANNEL_TEST'))
    parser.add_argument("--train-file", type=str, default="train.csv")
    parser.add_argument("--test-file", type=str, default="test.csv")

    argparse_args = parser.parse_args()
    print("Sklearn Version:", sklearn.__version__)
    print("joblib version:", joblib.__version__)

    print("[INFO] Reading data")
    print()
    train_df = pd.read_csv(os.path.join(argparse_args.train, argparse_args.train_file))
    test_df = pd.read_csv(os.path.join(argparse_args.test, argparse_args.test_file))

    features = list(train_df.columns)
    lable = features.pop(-1)
    print("building training and testing datasets")
    print()
    X_train = train_df[features]
    y_train = train_df[lable]
    X_test = test_df[features]
    y_test = test_df[lable]
    print('column order:')
    print(features)
    print()

    print("lable column is:", lable)
    print()
    print("data shape:")
    print()
    print("------SHAPE OF TRAINING DATA------")
    print(X_train.shape)
    print(y_train.shape)
    print()
    print("------SHAPE OF TESTING DATA------")
    print(X_test.shape)
    print(y_test.shape)
    print()
    print("Training randomforest model.....")
    print()
    model = RandomForestClassifier(n_estimators=100, random_state=1)
    model.fit(X_train, y_train)
    print("Training completed")
    model_path = os.path.join(argparse_args.model_dir, "model.joblib")
    print("Saving model to:", model_path)
    joblib.dump(model, model_path)
    print("model persisted at "+ model_path)
    print()

    y_pred_test = model.predict(X_test)
    print("Test Accuracy:", accuracy_score(y_test, y_pred_test))
    test_acc = accuracy_score(y_test, y_pred_test)
    test_rep = classification_report(y_test, y_pred_test)
    test_cm = confusion_matrix(y_test, y_pred_test)
    print()
    print("----METRICS RESULTS FOR TESTING DATA---")
    PRINT()
    PRINT("Total Rows are:", x_test.shape[0])
    print("Accuracy:", test_acc)
    print("Classification Report:")
    print(test_rep)
    print("Confusion Matrix:")
    print(test_cm)




from sagemaker.sklearn.estimator import SKLearn
framework_version='0.23-1'

sklearn_estimator = SKLearn(
    entry_point='script.py',
    role='arn:aws:iam::654654464583:user/Myiamuser',
    instance_count=1,
    instance_type='ml.m5.xlarge',
    framework_version=framework_version, # Align this line with other parameters
    base_job_name='heart-disease-prediction',
    hyperparameters={
        "max_depth": 5,
        "num_round": 0,
},
    use_spot_instance=True,
    max_wait=7200,
    max_run=3600,
)

%env AWS_DEFAULT_REGION=us-east-1

!export AWS_ACCESS_KEY_ID=AKIAZQ3DSMJDRNXBYRFJ
!export AWS_SECRET_ACCESS_KEY=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

sklearn_estimator = SKLearn(
    entry_point='script.py',  # Add the missing entry_point argument
    role='arn:aws:iam::654654464583:role/service-role/AmazonSageMaker-ExecutionRole-20240624T210799',
    instance_count=1,
    instance_type='ml.c5.2xlarge',
    framework_version=framework_version,
    base_job_name='heart-disease-prediction',
    hyperparameters={
        "n_estimators": 100,
        "random_state": 0,
},
    use_spot_instance=True,
    max_wait=7200,
    max_run=3600,
    output_path='s3://mysagemakerbucket55'
)

 sklearn_estimator = SKLearn(
    entry_point='script.py',
    role='arn:aws:iam::654654464583:role/service-role/AmazonSageMaker-ExecutionRole-20240624T210799',
    instance_count=1,
    instance_type='ml.m5.large',  # Change to an instance type with available quota
    framework_version=framework_version,
    base_job_name='heart-disease-prediction',
    # ... other parameters
)

# --- Applying Logistic Regression ---
LRclassifier = LogisticRegression(max_iter=1000, random_state=1, solver='liblinear', penalty='l1')
LRclassifier.fit(x_train, y_train)

y_pred_LR = LRclassifier.predict(x_test)


# --- LR Accuracy ---
LRAcc = accuracy_score(y_pred_LR, y_test)
print(' Logistic Regression Accuracy:'+'\033[1m {:.2f}%'.format(LRAcc*100)+' .:.')




# --- Applying KNN ---
KNNClassifier = KNeighborsClassifier(n_neighbors=3)
KNNClassifier.fit(x_train, y_train)

y_pred_KNN = KNNClassifier.predict(x_test)

# --- KNN Accuracy ---
KNNAcc = accuracy_score(y_pred_KNN, y_test)
print('.:. K-Nearest Neighbour Accuracy:'+'\033[1m {:.2f}%'.format(KNNAcc*100)+' .:.')

# --- Applying SVM ---
SVMclassifier = SVC(kernel='linear', max_iter=1000, C=10, probability=True)
SVMclassifier.fit(x_train, y_train)

y_pred_SVM = SVMclassifier.predict(x_test)

# --- SVM Accuracy ---
SVMAcc = accuracy_score(y_pred_SVM, y_test)
print('.:. Support Vector Machine Accuracy:'+'\033[1m {:.2f}%'.format(SVMAcc*100)+' .:.')

# --- Applying Decision Tree ---
DTCclassifier = DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, criterion='entropy', min_samples_split=5,
                                       splitter='random', random_state=1)

DTCclassifier.fit(x_train, y_train)
y_pred_DTC = DTCclassifier.predict(x_test)

# --- Decision Tree Accuracy ---
DTCAcc =accuracy_score(y_pred_DTC, y_test)
print(' Decision Tree Accuracy:'+'\033[1m {:.2f}%'.format(DTCAcc*100)+'' )

# --- Applying Random Forest ---
RFclassifier = RandomForestClassifier(n_estimators=1000, random_state=1, max_leaf_nodes=20, min_samples_split=15)

RFclassifier.fit(x_train, y_train)
y_pred_RF = RFclassifier.predict(x_test)

# --- Random Forest Accuracy ---
RFAcc = accuracy_score(y_pred_RF, y_test)
print(' Random Forest Accuracy:'+'\033[1m {:.2f}%'.format(RFAcc*100)+'')


# --- Create Accuracy Comparison Table ---
compare = pd.DataFrame({'Model': ['Logistic Regression', 'K-Nearest Neighbour', 'Support Vector Machine',
                                  'Decision Tree', 'Random Forest'],
                        'Accuracy': [LRAcc*100, KNNAcc*100, SVMAcc*100,DTCAcc*100, RFAcc*100,
                                     ]})

# --- Create Accuracy Comparison Table ---
# Remove .hide_index() for older pandas versions
compare.sort_values(by='Accuracy', ascending=False).style.background_gradient(cmap='PuRd').set_properties(**{'font-family': 'Segoe UI'})
